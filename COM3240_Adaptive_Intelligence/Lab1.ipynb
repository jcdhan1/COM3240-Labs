{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Intelligence COM3240\n",
    "## Lab 1: Learning and Remembering with the Hebbian rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturers and Lab Assistants###\n",
    "\n",
    "- Prof. Eleni Vasilaki ~ e.vasilaki@sheffield.ac.uk\n",
    "- Avgoustinos Vouros ~ avouros1@sheffield.ac.uk\n",
    "- Fariba Yousefi ~ f.yousefi@sheffield.ac.uk\n",
    "- Harry Jackson ~ hjackson3@sheffield.ac.uk\n",
    "- Daniel Camilleri ~ d.camilleri@sheffield.ac.uk\n",
    "\n",
    "### Lab Organisation\n",
    "- Task presentation and brief overview of few useful concepts you saw during the lecture.\n",
    "- You will be given a code you can run and play with and you will be asked to answer few basic questions about it.\n",
    "- You can finish the task at home for next week.\n",
    "\n",
    "### Learning Outcomes\n",
    "- Start to be familiar with some Python / MATLAB tools.\n",
    "- Understand the role of Hebbian learning rule.\n",
    "- Understand the difference between Hebbian and anti-Hebbian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Overview\n",
    "\n",
    "### The task: Learn and remember an object\n",
    "\n",
    "Remembering implies storing and retrieving information:\n",
    "- Phase I: Learning\n",
    "- Phase II: Recalling\n",
    "\n",
    "<img src='./gif/lab1_an1.gif'>\n",
    "\n",
    "### Hebbian Learning\n",
    "Connections can change depending on the activity of the two neurons involved: \n",
    "$$\\begin{align}\n",
    "w = w + \\gamma v_1 v_2 && \\gamma > 0 \n",
    "\\end{align}$$\n",
    "\n",
    "<img src='./icons/notes_fig1.jpg'>\n",
    "          \n",
    "### Anti-Hebbian Learning\n",
    "By applying the opposite change to a connection, we can erase what we have previously learnt: \n",
    "$$\\begin{align}\n",
    "w = w - \\gamma v_1 v_2 && \\gamma >0\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "<img src='./icons/notes_fig2.jpg'>\n",
    "          \n",
    "### Input and output signals\n",
    "Unless directly injected into the neuron, inputs come from other neurons through synapses:\n",
    "<img src='./icons/input_and_output_signals_1.png'>\n",
    "\n",
    "A two-step process takes place in the neuron whenever an input signal is registered.\n",
    "\n",
    "<img src='./icons/input_and_output_signals_2.png'>\n",
    "\n",
    "$I_A - W_AV_A \\text{ and } I_B - W_BV_V \\Rightarrow I_{TOT}= I_A + I_B = w_A V_A + w_B V_B = [w_a w_b]\\begin{bmatrix} V_a \\\\ V_b \\end{bmatrix} $\n",
    "\n",
    "**Conceptual meaning:** if the total input received is too small it does not wake up the neuron, whereas the more the input increases above the threshold θ the more the neuron will be active up to a certain maximum value.\n",
    "\n",
    "High connection increases the input, which in turn makes the firing more likely.\n",
    "\n",
    "<img src='./icons/input_and_output_signals_3.png'>\n",
    "\n",
    "After n loop iterations presenting the input image, the activity ν of all neurons reproduces the input pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 1: Learning and Remembering with the Hebbian rule\n",
    "\n",
    "### Questions:\n",
    "1. Detect which part of the code implements the Hebbian learning rule.\n",
    "2. Detect which part of the code implements the semi-linear neuron.\n",
    "3. Identify the value of the threshold θ used in the semi-linear neuron model.\n",
    "4. Change the value of the variable 'external_signal' from 2 to 0.5. Describe what happens and why.\n",
    "5. Implement Anti-Hebbian learning to erase the letter 'H' and learn a new letter (i.e. 'T')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import numpy as np                # docs.scipy.org/doc/numpy-1.10.0/reference/\n",
    "import matplotlib.pyplot as plt   # matplotlib.org/api/pyplot_summary.html\n",
    "\n",
    "%matplotlib inline                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input - a matrix of pixels displaying an alphabetical letter\n",
    "in_pixels = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "         \n",
    "[m, n] = in_pixels.shape            # dimensions of the input matrix: m-->number of rows, n-->number of columns\n",
    "N = np.size(in_pixels)              # (N = m*n) number of pixels == number of neurons in the neural network behind the input: each neuron is connected with one pixel\n",
    "\n",
    "# Display the input\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6, 8)) # opens a separate window where to plot the figure and assigns it a title\n",
    "# creates a 2-dimensional image of a matrix by assigning a colour to each value of the matrix depending on the value itself:\n",
    "# high values-->brighter, low values-->darker \n",
    "# interpolation = 'nearest' -> removes blurry effect due to interpolation\n",
    "# cmap = 'viridis'           -> selects the scale of colours we want to use\n",
    "img = ax.imshow(in_pixels, interpolation='nearest', cmap='viridis')\n",
    "\n",
    "ax.set_title('Input', fontsize=15);  # assign title to figure;\n",
    "\n",
    "# Add colorbar\n",
    "# This just makes the cmap to be shown properly rather than overlapping onto the plots\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes('right', \"5%\", pad = \"3%\")\n",
    "cm = fig.colorbar(img, cax =  cax)  # displays the color bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 : training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "gamma = 0.01          # learning rate\n",
    "threshold = 1         # firing threshold when the total input to a neuron reaches this value than the neuron fires\n",
    "freq_max = 10         # maximum allowed frequency\n",
    "w_init_max = 0.0005   # maximum value of initial weights (or connections) distribution\n",
    "external_signal = 2   # firing rate due to external input, when present\n",
    "\n",
    "niter = 10            # number of iterations\n",
    "\n",
    "# Initial conditions\n",
    "w = w_init_max * np.random.rand(N,N)                    # initial weights matrix: each neuron is connected with all the other neurons through a random connection between 0 and w_init_max\n",
    "np.fill_diagonal(w,0)                                   # set to zero all elements on the principal diagonal (auto interaction)\n",
    "neurons_freq = np.zeros([N,1])                          # initial value of the firing rate-->zero\n",
    "external_input = external_signal * in_pixels            # each neuron receives or not an external input equal to external_signal depending whether the pixel it is connected to is active (1) or not (0)\n",
    "external_input = np.reshape(external_input, (N,1))      # rearrange the N elements of the mxn matrix of external inputs into a vector Nx1, to simplify the operations below\n",
    "\n",
    "# Training loop\n",
    "for j in range(niter):\n",
    "    neurons_total_input = external_input + np.dot(w, neurons_freq)\n",
    "    neurons_output = np.maximum((neurons_total_input - threshold), 0)   # Element-wise maximum of array elements\n",
    "    neurons_freq = np.minimum(neurons_output, freq_max)                 # Element-wise minimum of array elements\n",
    "    w = w + gamma * np.dot(neurons_freq, neurons_freq.T)\n",
    "    np.fill_diagonal(w,0)\n",
    "\n",
    "\n",
    "# Display the output\n",
    "out_pixels = np.reshape(neurons_freq, (n, m))           # inverse conversion from vector to n x m matrix\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6, 8)) # opens a separate window where to plot the figure and assigns it a title\n",
    "# creates a 2-dimensional image of a matrix by assigning a colour to each value of the matrix depending on the value itself:\n",
    "# high values-->brighter, low values-->darker \n",
    "# interpolation = 'nearest' -> removes blurry effect due to interpolation\n",
    "# cmap = 'viridis'           -> selects the scale of colours we want to use\n",
    "img = ax.imshow(out_pixels, interpolation='nearest', cmap='viridis')\n",
    "\n",
    "ax.set_title('Firing rates after training', fontsize=15);  # assign title to figure;\n",
    "\n",
    "# Add colorbar\n",
    "# This just makes the cmap to be shown properly rather than overlapping onto the plots\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes('right', \"5%\", pad = \"3%\")\n",
    "cm = fig.colorbar(img, cax =  cax) # displays the color bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:  recalling image from partial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroy the input at random locations\n",
    "partial_input = in_pixels * np.random.randint(2, size=(m,n))\n",
    "\n",
    "# Show the consequent partial input\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize =(12, 14))\n",
    "img1 = ax1.imshow(partial_input, interpolation='nearest', cmap='viridis')\n",
    "ax1.set_title('Partial Input', fontsize=15)\n",
    "\n",
    "# Recalling operation\n",
    "external_input_partial = external_signal * np.reshape(partial_input, (N, 1))\n",
    "neurons_freq_new = np.zeros([N,1])\n",
    "\n",
    "for j in range(niter):\n",
    "   neurons_freq_new = np.maximum(((external_input_partial + np.dot(w, neurons_freq_new)) - threshold), 0)\n",
    "   neurons_freq_new = np.minimum(neurons_freq_new, freq_max)\n",
    "\n",
    "\n",
    "# Display the output\n",
    "out_pixels_reconstruction = np.reshape(neurons_freq_new, (n, m))\n",
    "\n",
    "\n",
    "img2 = ax2.imshow(out_pixels_reconstruction, interpolation='nearest', cmap='viridis')\n",
    "ax2.set_title('Recalled output', fontsize=15)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "\n",
    "# This just makes the cmap to be shown properly rather than overlapping onto the plots\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes('right', \"5%\", pad = \"3%\")\n",
    "cm = fig.colorbar(img, cax =  cax)\n",
    "\n",
    "\n",
    "# Make the colors for images match the colorbar range\n",
    "img1.set_clim(vmin=0, vmax=freq_max)\n",
    "img2.set_clim(vmin=0, vmax=freq_max)\n",
    "cm.set_clim(vmin=0, vmax=freq_max)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Forgetting image via Anti-Hebb rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Implement the anti-hebbian learning rule in order to forget the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Demonstrating that the image is erased "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Demostrate that there is not recollection of the image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
